#!/usr/bin/env python3
"""
ç°ä»£åŒ–è®ºæ–‡åˆ†ææ¨¡å—

ä½¿ç”¨AIæŠ€æœ¯å¯¹è®ºæ–‡è¿›è¡Œæ·±åº¦åˆ†æã€ç†è§£å’ŒæŠ¥å‘Šç”Ÿæˆã€‚
"""

import logging
from datetime import datetime
from typing import Any

# ç¬¬ä¸‰æ–¹åº“
import httpx

# å†…éƒ¨æ¨¡å—
from ..models.config import AppConfig

logger = logging.getLogger(__name__)


class PaperAnalyzer:
    """ç°ä»£åŒ–è®ºæ–‡åˆ†æå™¨ - ä½¿ç”¨AIè¿›è¡Œæ·±åº¦åˆ†æ"""

    def __init__(self, config: AppConfig):
        """
        åˆå§‹åŒ–è®ºæ–‡åˆ†æå™¨

        Args:
            config: åº”ç”¨ç¨‹åºé…ç½®
        """
        self.config = config
        self.api_key = config.get_llm_api_key()
        self.base_url = config.llm.api_base_url
        self.model = config.llm.default_model

        if not self.api_key:
            logger.warning("æœªæ‰¾åˆ°LLM APIå¯†é’¥ï¼Œåˆ†æåŠŸèƒ½å°†è¢«ç¦ç”¨")
            logger.info("è¯·åœ¨é…ç½®ä¸­è®¾ç½®LLM APIå¯†é’¥")

    def is_enabled(self) -> bool:
        """æ£€æŸ¥åˆ†æå™¨æ˜¯å¦å¯ç”¨"""
        return bool(self.api_key)

    async def _call_llm(self, prompt: str, max_tokens: int = 2000) -> str | None:
        """
        å¼‚æ­¥è°ƒç”¨LLM API

        Args:
            prompt: æç¤ºè¯
            max_tokens: æœ€å¤§tokenæ•°

        Returns:
            LLMå“åº”å†…å®¹
        """
        if not self.is_enabled():
            return None

        try:
            headers = {
                "Authorization": f"Bearer {self.api_key}",
                "Content-Type": "application/json",
                "HTTP-Referer": "https://github.com/arxiv-follow",
                "X-Title": "ArXiv Follow Paper Analysis Service",
            }

            data = {
                "model": self.model,
                "messages": [{"role": "user", "content": prompt}],
                "max_tokens": max_tokens,
                "temperature": 0.3,
                "top_p": 0.9,
            }

            async with httpx.AsyncClient(timeout=60.0) as client:
                response = await client.post(
                    f"{self.base_url}/chat/completions", headers=headers, json=data
                )
                response.raise_for_status()

                result = response.json()
                content = result["choices"][0]["message"]["content"]

                logger.info(f"LLMåˆ†æå®Œæˆï¼Œå“åº”é•¿åº¦: {len(content)}")
                return content

        except Exception as e:
            logger.error(f"LLM APIè°ƒç”¨å¤±è´¥: {e}")
            return None

    async def analyze_paper_significance(
        self, paper_data: dict[str, Any]
    ) -> dict[str, Any]:
        """
        åˆ†æè®ºæ–‡çš„é‡è¦æ€§å’Œæ„ä¹‰

        Args:
            paper_data: è®ºæ–‡æ•°æ®

        Returns:
            é‡è¦æ€§åˆ†æç»“æœ
        """
        if not self.is_enabled():
            return {
                "error": "åˆ†æå™¨æœªå¯ç”¨",
                "success": False,
                "importance_score": 5.0,  # é»˜è®¤ä¸­ç­‰é‡è¦æ€§
            }

        # æ„å»ºåˆ†ææç¤ºè¯
        title = paper_data.get("title", "æœªçŸ¥æ ‡é¢˜")
        abstract = paper_data.get("summary", paper_data.get("abstract", "æ— æ‘˜è¦"))
        authors = paper_data.get("authors", [])
        categories = paper_data.get("categories", [])

        prompt = f"""è¯·åˆ†æä»¥ä¸‹å­¦æœ¯è®ºæ–‡çš„é‡è¦æ€§å’Œæ„ä¹‰ï¼š

è®ºæ–‡æ ‡é¢˜ï¼š{title}

ä½œè€…ï¼š{', '.join(authors) if authors else 'æœªçŸ¥'}

åˆ†ç±»ï¼š{', '.join(categories) if categories else 'æœªçŸ¥'}

æ‘˜è¦ï¼š
{abstract}

è¯·ä»ä»¥ä¸‹è§’åº¦è¿›è¡Œåˆ†æï¼ˆç”¨ä¸­æ–‡å›ç­”ï¼‰ï¼š

1. **ç ”ç©¶æ„ä¹‰**ï¼šè¿™ä¸ªç ”ç©¶è§£å†³äº†ä»€ä¹ˆé—®é¢˜ï¼Ÿä¸ºä»€ä¹ˆé‡è¦ï¼Ÿ
2. **æŠ€æœ¯åˆ›æ–°ç‚¹**ï¼šæœ‰å“ªäº›æ–°çš„æ–¹æ³•ã€æŠ€æœ¯æˆ–ç†è®ºè´¡çŒ®ï¼Ÿ
3. **åº”ç”¨ä»·å€¼**ï¼šå¯èƒ½çš„å®é™…åº”ç”¨åœºæ™¯å’Œå½±å“ï¼Ÿ
4. **ç ”ç©¶è´¨é‡è¯„ä¼°**ï¼šåŸºäºæ‘˜è¦åˆ¤æ–­ç ”ç©¶çš„ä¸¥è°¨æ€§å’Œå®Œæ•´æ€§
5. **é‡è¦æ€§è¯„åˆ†**ï¼šç»™å‡º1-10åˆ†çš„é‡è¦æ€§è¯„åˆ†ï¼ˆ10åˆ†æœ€é«˜ï¼‰
6. **å…³é”®è¯æå–**ï¼šæå–5-8ä¸ªå…³é”®æŠ€æœ¯è¯æ±‡

è¯·ç”¨ç»“æ„åŒ–çš„æ–¹å¼å›ç­”ï¼Œæ¯ä¸ªéƒ¨åˆ†ç”¨ç®€æ´ä½†æœ‰è§åœ°çš„è¯­è¨€æ€»ç»“ã€‚
æœ€åè¯·åœ¨æœ€åä¸€è¡Œå•ç‹¬è¾“å‡ºé‡è¦æ€§è¯„åˆ†ï¼Œæ ¼å¼ä¸º"é‡è¦æ€§è¯„åˆ†: X.X"
"""

        response = await self._call_llm(prompt, max_tokens=1500)

        if response:
            # å°è¯•æå–é‡è¦æ€§è¯„åˆ†
            importance_score = 5.0  # é»˜è®¤è¯„åˆ†
            try:
                # æŸ¥æ‰¾è¯„åˆ†æ¨¡å¼
                lines = response.split("\n")
                for line in lines:
                    if "é‡è¦æ€§è¯„åˆ†" in line or "è¯„åˆ†" in line:
                        import re

                        score_match = re.search(r"(\d+\.?\d*)", line)
                        if score_match:
                            importance_score = float(score_match.group(1))
                            break
            except (ValueError, AttributeError):
                pass

            return {
                "analysis_type": "significance",
                "content": response,
                "model": self.model,
                "analysis_time": datetime.now().isoformat(),
                "importance_score": importance_score,
                "success": True,
            }
        else:
            return {"error": "LLMåˆ†æå¤±è´¥", "success": False, "importance_score": 5.0}

    async def analyze_paper_technical_details(
        self, paper_data: dict[str, Any]
    ) -> dict[str, Any]:
        """
        åˆ†æè®ºæ–‡çš„æŠ€æœ¯ç»†èŠ‚

        Args:
            paper_data: è®ºæ–‡æ•°æ®

        Returns:
            æŠ€æœ¯åˆ†æç»“æœ
        """
        if not self.is_enabled():
            return {"error": "åˆ†æå™¨æœªå¯ç”¨", "success": False}

        title = paper_data.get("title", "æœªçŸ¥æ ‡é¢˜")
        abstract = paper_data.get("summary", paper_data.get("abstract", "æ— æ‘˜è¦"))

        prompt = f"""è¯·å¯¹ä»¥ä¸‹å­¦æœ¯è®ºæ–‡è¿›è¡ŒæŠ€æœ¯æ·±åº¦åˆ†æï¼š

è®ºæ–‡æ ‡é¢˜ï¼š{title}

æ‘˜è¦ï¼š
{abstract}

è¯·ä»æŠ€æœ¯è§’åº¦è¿›è¡Œè¯¦ç»†åˆ†æï¼ˆç”¨ä¸­æ–‡å›ç­”ï¼‰ï¼š

1. **æ–¹æ³•è®ºåˆ†æ**ï¼šä½¿ç”¨äº†å“ªäº›ç ”ç©¶æ–¹æ³•å’ŒæŠ€æœ¯æ‰‹æ®µï¼Ÿ
2. **ç®—æ³•/æ¨¡å‹è¯¦è§£**ï¼šæ ¸å¿ƒç®—æ³•æˆ–æ¨¡å‹çš„å·¥ä½œåŸç†æ˜¯ä»€ä¹ˆï¼Ÿ
3. **å®éªŒè®¾è®¡**ï¼šå®éªŒæ˜¯å¦‚ä½•è®¾è®¡çš„ï¼Ÿä½¿ç”¨äº†ä»€ä¹ˆæ•°æ®é›†ï¼Ÿ
4. **æŠ€æœ¯éš¾ç‚¹**ï¼šè§£å†³äº†å“ªäº›æŠ€æœ¯æŒ‘æˆ˜ï¼Ÿ
5. **ä¸ç°æœ‰å·¥ä½œçš„å…³ç³»**ï¼šå¦‚ä½•åœ¨ç°æœ‰ç ”ç©¶åŸºç¡€ä¸Šæ”¹è¿›ï¼Ÿ
6. **å¯é‡ç°æ€§è¯„ä¼°**ï¼šå®éªŒçš„å¯é‡ç°æ€§å¦‚ä½•ï¼Ÿ
7. **æŠ€æœ¯å±€é™æ€§**ï¼šå­˜åœ¨å“ªäº›æŠ€æœ¯é™åˆ¶æˆ–ä¸è¶³ï¼Ÿ

è¯·ç”¨ä¸“ä¸šä½†æ˜“æ‡‚çš„è¯­è¨€è¿›è¡Œåˆ†æï¼Œé‡ç‚¹çªå‡ºæŠ€æœ¯è´¡çŒ®ã€‚
"""

        response = await self._call_llm(prompt, max_tokens=2000)

        if response:
            return {
                "analysis_type": "technical",
                "content": response,
                "model": self.model,
                "analysis_time": datetime.now().isoformat(),
                "success": True,
            }
        else:
            return {"error": "LLMåˆ†æå¤±è´¥", "success": False}

    async def generate_comprehensive_report(
        self, paper_data: dict[str, Any]
    ) -> dict[str, Any]:
        """
        ç”Ÿæˆç»¼åˆåˆ†ææŠ¥å‘Š

        Args:
            paper_data: è®ºæ–‡æ•°æ®

        Returns:
            ç»¼åˆåˆ†ææŠ¥å‘Š
        """
        if not self.is_enabled():
            return {"error": "åˆ†æå™¨æœªå¯ç”¨", "success": False}

        # å¹¶è¡Œæ‰§è¡Œå¤šç§åˆ†æ
        significance_task = self.analyze_paper_significance(paper_data)
        technical_task = self.analyze_paper_technical_details(paper_data)

        try:
            significance_result = await significance_task
            technical_result = await technical_task

            return {
                "analysis_type": "comprehensive",
                "paper_info": {
                    "title": paper_data.get("title", "æœªçŸ¥æ ‡é¢˜"),
                    "authors": paper_data.get("authors", []),
                    "arxiv_id": paper_data.get("arxiv_id", paper_data.get("id", "")),
                    "categories": paper_data.get("categories", []),
                },
                "significance_analysis": significance_result,
                "technical_analysis": technical_result,
                "overall_score": significance_result.get("importance_score", 5.0),
                "analysis_time": datetime.now().isoformat(),
                "success": True,
            }

        except Exception as e:
            logger.error(f"ç»¼åˆåˆ†æå¤±è´¥: {e}")
            return {"error": f"ç»¼åˆåˆ†æå¤±è´¥: {str(e)}", "success": False}

    async def analyze_multiple_papers(
        self, papers_data: list[dict[str, Any]], mode: str = "significance"
    ) -> list[dict[str, Any]]:
        """
        æ‰¹é‡åˆ†æå¤šç¯‡è®ºæ–‡

        Args:
            papers_data: è®ºæ–‡æ•°æ®åˆ—è¡¨
            mode: åˆ†ææ¨¡å¼ ("significance", "technical", "comprehensive")

        Returns:
            åˆ†æç»“æœåˆ—è¡¨
        """
        if not self.is_enabled():
            return [{"error": "åˆ†æå™¨æœªå¯ç”¨", "success": False} for _ in papers_data]

        if not papers_data:
            return []

        logger.info(f"å¼€å§‹æ‰¹é‡åˆ†æ {len(papers_data)} ç¯‡è®ºæ–‡ï¼Œæ¨¡å¼: {mode}")

        results = []

        # æ ¹æ®æ¨¡å¼é€‰æ‹©åˆ†ææ–¹æ³•
        if mode == "significance":
            analyze_func = self.analyze_paper_significance
        elif mode == "technical":
            analyze_func = self.analyze_paper_technical_details
        elif mode == "comprehensive":
            analyze_func = self.generate_comprehensive_report
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„åˆ†ææ¨¡å¼: {mode}")

        # æ‰¹é‡å¤„ç†ï¼ˆè¿™é‡Œå¯ä»¥æ ¹æ®éœ€è¦è°ƒæ•´å¹¶å‘åº¦ï¼‰
        import asyncio

        semaphore = asyncio.Semaphore(3)  # é™åˆ¶å¹¶å‘æ•°

        async def analyze_with_semaphore(paper_data):
            async with semaphore:
                return await analyze_func(paper_data)

        tasks = [analyze_with_semaphore(paper) for paper in papers_data]
        results = await asyncio.gather(*tasks, return_exceptions=True)

        # å¤„ç†å¼‚å¸¸ç»“æœ
        processed_results = []
        for i, result in enumerate(results):
            if isinstance(result, Exception):
                logger.error(f"è®ºæ–‡ {i} åˆ†æå¤±è´¥: {result}")
                processed_results.append({"error": str(result), "success": False})
            else:
                processed_results.append(result)

        logger.info(
            f"æ‰¹é‡åˆ†æå®Œæˆï¼ŒæˆåŠŸ: {sum(1 for r in processed_results if r.get('success'))}/{len(processed_results)}"
        )

        return processed_results

    def generate_daily_summary(
        self, papers_analysis: list[dict[str, Any]]
    ) -> dict[str, Any]:
        """
        ç”Ÿæˆæ¯æ—¥åˆ†ææ‘˜è¦

        Args:
            papers_analysis: è®ºæ–‡åˆ†æç»“æœåˆ—è¡¨

        Returns:
            æ¯æ—¥æ‘˜è¦
        """
        summary = {
            "date": datetime.now().strftime("%Y-%m-%d"),
            "total_papers": len(papers_analysis),
            "successful_analysis": sum(1 for p in papers_analysis if p.get("success")),
            "failed_analysis": sum(1 for p in papers_analysis if not p.get("success")),
            "average_importance": 0.0,
            "high_importance_papers": [],
            "top_categories": {},
            "summary_text": "",
        }

        # ç»Ÿè®¡æˆåŠŸåˆ†æçš„è®ºæ–‡
        successful_papers = [p for p in papers_analysis if p.get("success")]

        if successful_papers:
            # è®¡ç®—å¹³å‡é‡è¦æ€§
            scores = [
                p.get("importance_score", 5.0)
                for p in successful_papers
                if p.get("importance_score")
            ]
            if scores:
                summary["average_importance"] = sum(scores) / len(scores)

            # ç­›é€‰é«˜é‡è¦æ€§è®ºæ–‡ï¼ˆ> 7.0åˆ†ï¼‰
            high_importance = [
                p for p in successful_papers if p.get("importance_score", 0) > 7.0
            ]
            summary["high_importance_papers"] = high_importance[:5]  # æœ€å¤š5ç¯‡

            # ç»Ÿè®¡åˆ†ç±»åˆ†å¸ƒ
            categories = {}
            for paper in successful_papers:
                paper_categories = paper.get("paper_info", {}).get("categories", [])
                for cat in paper_categories:
                    categories[cat] = categories.get(cat, 0) + 1

            # å–å‰5ä¸ªåˆ†ç±»
            summary["top_categories"] = dict(
                sorted(categories.items(), key=lambda x: x[1], reverse=True)[:5]
            )

            # ç”Ÿæˆæ‘˜è¦æ–‡æœ¬
            summary["summary_text"] = self._generate_summary_text(summary)

        return summary

    def _generate_summary_text(self, summary: dict[str, Any]) -> str:
        """ç”Ÿæˆå¯è¯»çš„æ‘˜è¦æ–‡æœ¬"""
        parts = []

        parts.append(f"ğŸ“Š ä»Šæ—¥å…±åˆ†æ {summary['total_papers']} ç¯‡è®ºæ–‡")
        parts.append(f"âœ… æˆåŠŸåˆ†æ {summary['successful_analysis']} ç¯‡")

        if summary["failed_analysis"] > 0:
            parts.append(f"âŒ åˆ†æå¤±è´¥ {summary['failed_analysis']} ç¯‡")

        if summary["average_importance"] > 0:
            parts.append(f"ğŸ“ˆ å¹³å‡é‡è¦æ€§è¯„åˆ† {summary['average_importance']:.1f}/10")

        if summary["high_importance_papers"]:
            parts.append(
                f"â­ å‘ç° {len(summary['high_importance_papers'])} ç¯‡é«˜é‡è¦æ€§è®ºæ–‡"
            )

        if summary["top_categories"]:
            top_cat = list(summary["top_categories"].keys())[0]
            parts.append(f"ğŸ”¥ çƒ­é—¨åˆ†ç±»: {top_cat}")

        return "\n".join(parts)


# ä¾¿æ·å‡½æ•°
async def analyze_paper(
    paper_data: dict[str, Any], config: AppConfig, mode: str = "comprehensive"
) -> dict[str, Any]:
    """
    åˆ†æå•ç¯‡è®ºæ–‡çš„ä¾¿æ·å‡½æ•°

    Args:
        paper_data: è®ºæ–‡æ•°æ®
        config: åº”ç”¨é…ç½®
        mode: åˆ†ææ¨¡å¼

    Returns:
        åˆ†æç»“æœ
    """
    analyzer = PaperAnalyzer(config)

    if mode == "significance":
        return await analyzer.analyze_paper_significance(paper_data)
    elif mode == "technical":
        return await analyzer.analyze_paper_technical_details(paper_data)
    elif mode == "comprehensive":
        return await analyzer.generate_comprehensive_report(paper_data)
    else:
        raise ValueError(f"ä¸æ”¯æŒçš„åˆ†ææ¨¡å¼: {mode}")


async def analyze_multiple_papers(
    papers_data: list[dict[str, Any]], config: AppConfig, mode: str = "comprehensive"
) -> list[dict[str, Any]]:
    """
    æ‰¹é‡åˆ†æè®ºæ–‡çš„ä¾¿æ·å‡½æ•°

    Args:
        papers_data: è®ºæ–‡æ•°æ®åˆ—è¡¨
        config: åº”ç”¨é…ç½®
        mode: åˆ†ææ¨¡å¼

    Returns:
        åˆ†æç»“æœåˆ—è¡¨
    """
    analyzer = PaperAnalyzer(config)
    return await analyzer.analyze_multiple_papers(papers_data, mode)


if __name__ == "__main__":
    # æµ‹è¯•ä»£ç 
    import asyncio

    from ..models.config import AppConfig

    async def test_analyzer():
        print("ğŸ§ª æµ‹è¯•è®ºæ–‡åˆ†æåŠŸèƒ½")

        config = AppConfig()
        analyzer = PaperAnalyzer(config)

        print(f"åˆ†æå™¨çŠ¶æ€: {'å¯ç”¨' if analyzer.is_enabled() else 'ç¦ç”¨'}")

        if analyzer.is_enabled():
            # æµ‹è¯•è®ºæ–‡æ•°æ®
            test_paper = {
                "title": "Deep Learning for Cybersecurity Applications",
                "authors": ["Zhang Wei", "Li Ming"],
                "abstract": "This paper presents novel deep learning approaches for cybersecurity...",
                "categories": ["cs.CR", "cs.LG"],
            }

            result = await analyzer.analyze_paper_significance(test_paper)
            print(f"åˆ†æç»“æœ: {result.get('success', False)}")
            print(f"é‡è¦æ€§è¯„åˆ†: {result.get('importance_score', 'N/A')}")

    asyncio.run(test_analyzer())
