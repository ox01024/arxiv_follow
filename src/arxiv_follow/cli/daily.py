#!/usr/bin/env python3
"""
æ¯æ—¥ç ”ç©¶è€…åŠ¨æ€ç›‘æ§è„šæœ¬ - æœç´¢ç‰¹å®šç ”ç©¶è€…å½“å¤©å‘å¸ƒçš„è®ºæ–‡
"""

from datetime import datetime
from typing import Any

import httpx

# å¯¼å…¥æ»´ç­”æ¸…å•é›†æˆå’Œé…ç½®
try:
    from ..config.settings import DIDA_API_CONFIG
    from ..integrations.dida import create_arxiv_task
    from ..services.researcher import (
        build_arxiv_search_url,
        fetch_researchers_from_tsv,
        parse_arxiv_search_results,
    )
except ImportError:
    print("âš ï¸ æ— æ³•å¯¼å…¥é›†æˆæ¨¡å—ï¼Œç›¸å…³åŠŸèƒ½å°†è¢«ç¦ç”¨")

    def create_arxiv_task(*_args, **_kwargs):
        return {"success": False, "error": "æ¨¡å—æœªå¯¼å…¥"}

    def fetch_researchers_from_tsv(*_args, **_kwargs):
        return []

    def build_arxiv_search_url(*_args, **_kwargs):
        return ""

    def parse_arxiv_search_results(*_args, **_kwargs):
        return []

    DIDA_API_CONFIG = {"enable_bilingual": True}


def fetch_papers_for_researcher(
    author_name: str, date_from: str, date_to: str
) -> list[dict[str, Any]]:
    """
    è·å–ç‰¹å®šç ”ç©¶è€…åœ¨æŒ‡å®šæ—¥æœŸèŒƒå›´å†…çš„è®ºæ–‡

    Args:
        author_name: ç ”ç©¶è€…å§“å
        date_from: å¼€å§‹æ—¥æœŸ
        date_to: ç»“æŸæ—¥æœŸ

    Returns:
        è®ºæ–‡åˆ—è¡¨
    """
    try:
        # æ„å»ºæœç´¢URL
        search_url = build_arxiv_search_url(author_name, date_from, date_to)
        print(f"æœç´¢ {author_name} çš„è®ºæ–‡: {search_url}")

        # è·å–æœç´¢ç»“æœé¡µé¢
        with httpx.Client(follow_redirects=True, timeout=30.0) as client:
            response = client.get(search_url)
            response.raise_for_status()

        # è§£ææœç´¢ç»“æœ
        papers = parse_arxiv_search_results(response.text)

        # ä¸ºæ¯ç¯‡è®ºæ–‡æ·»åŠ æŸ¥è¯¢çš„ä½œè€…ä¿¡æ¯
        for paper in papers:
            paper["queried_author"] = author_name

        return papers

    except Exception as e:
        print(f"è·å– {author_name} çš„è®ºæ–‡æ—¶å‡ºé”™: {e}")
        return []


def get_today_papers_for_all_researchers(
    researchers: list[dict[str, Any]],
) -> dict[str, list[dict[str, Any]]]:
    """
    è·å–æ‰€æœ‰ç ”ç©¶è€…ä»Šå¤©å‘å¸ƒçš„è®ºæ–‡

    Args:
        researchers: ç ”ç©¶è€…åˆ—è¡¨

    Returns:
        æŒ‰ç ”ç©¶è€…åˆ†ç»„çš„è®ºæ–‡å­—å…¸
    """
    # è·å–ä»Šå¤©çš„æ—¥æœŸ
    today = datetime.now()
    date_str = today.strftime("%Y-%m-%d")

    print(f"\nğŸ” æ­£åœ¨æœç´¢ {date_str} å½“å¤©å‘å¸ƒçš„è®ºæ–‡...")
    print("=" * 60)

    all_papers = {}

    for researcher in researchers:
        # è·å–ç ”ç©¶è€…å§“å
        if isinstance(researcher, dict):
            if "name" in researcher:
                author_name = researcher["name"]
            else:
                # å–ç¬¬ä¸€ä¸ªéç©ºå€¼ä½œä¸ºå§“å
                author_name = next((v for v in researcher.values() if v.strip()), "")
        else:
            author_name = str(researcher)

        if not author_name or author_name.lower() in ["aaa", "test"]:  # è·³è¿‡æµ‹è¯•æ•°æ®
            continue

        print(f"\næ­£åœ¨æœç´¢ {author_name} çš„è®ºæ–‡...")

        # è·å–è¯¥ç ”ç©¶è€…çš„è®ºæ–‡
        papers = fetch_papers_for_researcher(author_name, date_str, date_str)

        if papers:
            all_papers[author_name] = papers
            print(f"  âœ… æ‰¾åˆ° {len(papers)} ç¯‡è®ºæ–‡")
        else:
            print("  âŒ æœªæ‰¾åˆ°è®ºæ–‡")

    return all_papers


def display_papers(all_papers: dict[str, list[dict[str, Any]]]) -> None:
    """
    æ˜¾ç¤ºæ‰€æœ‰è®ºæ–‡

    Args:
        all_papers: æŒ‰ç ”ç©¶è€…åˆ†ç»„çš„è®ºæ–‡å­—å…¸
    """
    if not all_papers:
        print("\nğŸ“ ä»Šå¤©æ²¡æœ‰æ‰¾åˆ°æ–°è®ºæ–‡")
        return

    total_papers = sum(len(papers) for papers in all_papers.values())
    print(f"\nğŸ‰ ä»Šå¤©å…±æ‰¾åˆ° {total_papers} ç¯‡æ–°è®ºæ–‡!")
    print("=" * 80)

    for author, papers in all_papers.items():
        print(f"\nğŸ‘¨â€ğŸ”¬ {author} ({len(papers)} ç¯‡è®ºæ–‡):")
        print("-" * 40)

        for i, paper in enumerate(papers, 1):
            print(f"\n{i}. ğŸ“„ {paper.get('title', 'æœªçŸ¥æ ‡é¢˜')}")

            if "arxiv_id" in paper:
                print(f"   ğŸ”— arXiv ID: {paper['arxiv_id']}")
                print(f"   ğŸŒ é“¾æ¥: {paper.get('url', '')}")

            if "authors" in paper and paper["authors"]:
                # æ˜¾ç¤ºæ‰€æœ‰ä½œè€…
                authors_str = ", ".join(paper["authors"])
                print(f"   ğŸ‘¥ ä½œè€…: {authors_str}")

            if "submitted_date" in paper:
                print(f"   ğŸ“… æäº¤æ—¥æœŸ: {paper['submitted_date']}")

            if "abstract" in paper and paper["abstract"]:
                abstract = paper["abstract"]
                print(f"   ğŸ“ æ‘˜è¦: {abstract}")

            # æ˜¾ç¤ºå­¦ç§‘åˆ†ç±»
            if "subjects" in paper and paper["subjects"]:
                subjects_str = ", ".join(paper["subjects"])
                print(f"   ğŸ·ï¸ é¢†åŸŸ: {subjects_str}")

            # æ˜¾ç¤ºè¯„è®ºä¿¡æ¯
            if "comments" in paper and paper["comments"]:
                print(f"   ğŸ’¬ è¯„è®º: {paper['comments']}")


def display_researchers(researchers: list[dict[str, Any]]) -> None:
    """
    æ˜¾ç¤ºç ”ç©¶è€…åˆ—è¡¨

    Args:
        researchers: ç ”ç©¶è€…æ•°æ®åˆ—è¡¨
    """
    if not researchers:
        print("æ²¡æœ‰æ‰¾åˆ°ç ”ç©¶è€…æ•°æ®")
        return

    print(f"\næ‰¾åˆ° {len(researchers)} ä¸ªç ”ç©¶è€…:")
    print("=" * 50)

    for i, researcher in enumerate(researchers, 1):
        print(f"{i}. ", end="")

        if isinstance(researcher, dict):
            if "name" in researcher:
                print(f"å§“å: {researcher['name']}")
                # æ˜¾ç¤ºå…¶ä»–å­—æ®µ
                for key, value in researcher.items():
                    if key != "name" and key != "row_index" and value:
                        print(f"   {key}: {value}")
            else:
                # æ˜¾ç¤ºæ‰€æœ‰å­—æ®µ
                for key, value in researcher.items():
                    if value:
                        print(f"{key}: {value}")
        else:
            print(researcher)
        print()


def create_daily_dida_task(
    researchers: list[dict[str, Any]],
    all_papers: dict[str, list[dict[str, Any]]],
    error: str = None,
) -> None:
    """
    åˆ›å»ºæ¯æ—¥è®ºæ–‡ç›‘æ§çš„æ»´ç­”æ¸…å•ä»»åŠ¡

    Args:
        researchers: ç ”ç©¶è€…åˆ—è¡¨
        all_papers: è®ºæ–‡æ•°æ®
        error: é”™è¯¯ä¿¡æ¯ï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰
    """
    print("\nğŸ“ åˆ›å»ºæ»´ç­”æ¸…å•ä»»åŠ¡...")

    try:
        # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
        total_papers = (
            sum(len(papers) for papers in all_papers.values()) if all_papers else 0
        )
        researcher_count = len(researchers)

        # æ„å»ºä»»åŠ¡æ‘˜è¦ï¼ˆMarkdownæ ¼å¼ï¼‰
        if error:
            summary = f"âŒ **æ¯æ—¥ç ”ç©¶è€…åŠ¨æ€ç›‘æ§æ‰§è¡Œå¤±è´¥**\n\n**é”™è¯¯ä¿¡æ¯:** {error}"
            details = f"â° **æ‰§è¡Œæ—¶é—´:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}"
        elif total_papers == 0:
            summary = "ğŸ“„ **ä»Šæ—¥ç ”ç©¶è€…æ— æ–°è®ºæ–‡å‘å¸ƒ**"
            details = f"ğŸ‘¥ **ç›‘æ§ç ”ç©¶è€…:** {researcher_count} ä½\nâ° **æ‰§è¡Œæ—¶é—´:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}"
        else:
            summary = f"ğŸ‰ **ä»Šæ—¥ç ”ç©¶è€…å‘å¸ƒ {total_papers} ç¯‡æ–°è®ºæ–‡ï¼**"
            # æ„å»ºè¯¦ç»†ä¿¡æ¯ï¼ˆMarkdownæ ¼å¼ï¼‰
            details_lines = [f"ğŸ‘¥ **ç›‘æ§ç ”ç©¶è€…:** {researcher_count} ä½"]

            # æ·»åŠ å‘ç°è®ºæ–‡çš„ç ”ç©¶è€…è¯¦æƒ…ï¼ˆMarkdownæ ¼å¼ï¼‰
            if all_papers:
                details_lines.append("\n## ğŸ“Š è®ºæ–‡åˆ†å¸ƒ")
                for author, papers in all_papers.items():
                    details_lines.append(f"\n### ğŸ‘¨â€ğŸ”¬ {author} ({len(papers)} ç¯‡)")

                    # æ˜¾ç¤ºæ‰€æœ‰è®ºæ–‡çš„è¯¦ç»†ä¿¡æ¯
                    for i, paper in enumerate(papers, 1):
                        title = paper.get("title", "æœªçŸ¥æ ‡é¢˜")
                        arxiv_id = paper.get("arxiv_id", "")
                        url = paper.get("url", "")

                        # ä½¿ç”¨Markdowné“¾æ¥æ ¼å¼
                        if url and arxiv_id:
                            details_lines.append(f"\n**{i}. [{title}]({url})**")
                            details_lines.append(f"ğŸ“„ **arXiv:** `{arxiv_id}`")
                        else:
                            details_lines.append(f"\n**{i}. {title}**")

                        # ä½œè€…ä¿¡æ¯ï¼ˆæ˜¾ç¤ºæ‰€æœ‰ä½œè€…ï¼‰
                        if paper.get("authors"):
                            authors_str = ", ".join(paper["authors"])
                            details_lines.append(f"ğŸ‘¥ **ä½œè€…:** {authors_str}")

                        # æ‘˜è¦ä¿¡æ¯ï¼ˆå‰200å­—ç¬¦ï¼‰
                        if paper.get("abstract"):
                            abstract = paper["abstract"]

                            details_lines.append(f"ğŸ“ **æ‘˜è¦:** {abstract}")

                        # æäº¤æ—¥æœŸ
                        if paper.get("submitted_date"):
                            details_lines.append(
                                f"ğŸ“… **æäº¤æ—¥æœŸ:** {paper['submitted_date']}"
                            )

                        # å­¦ç§‘åˆ†ç±»ï¼ˆæ˜¾ç¤ºæ‰€æœ‰åˆ†ç±»ï¼‰
                        if paper.get("subjects"):
                            subjects_str = ", ".join(
                                [f"`{s}`" for s in paper["subjects"]]
                            )
                            details_lines.append(f"ğŸ·ï¸ **é¢†åŸŸ:** {subjects_str}")

                        # è¯„è®ºä¿¡æ¯
                        if paper.get("comments"):
                            comments = paper["comments"]

                            details_lines.append(f"ğŸ’¬ **è¯„è®º:** {comments}")

                        details_lines.append("---")  # åˆ†éš”çº¿

            details_lines.append(
                f"\nâ° **æ‰§è¡Œæ—¶é—´:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}"
            )
            details = "\n".join(details_lines)

        # åˆ›å»ºä»»åŠ¡ï¼ˆæ”¯æŒåŒè¯­ç¿»è¯‘ï¼‰
        bilingual_enabled = DIDA_API_CONFIG.get("enable_bilingual", False)
        result = create_arxiv_task(
            report_type="daily",
            summary=summary,
            details=details,
            paper_count=total_papers,
            bilingual=bilingual_enabled,
        )

        if result.get("success"):
            print("âœ… æ»´ç­”æ¸…å•ä»»åŠ¡åˆ›å»ºæˆåŠŸ!")
            if result.get("task_id"):
                print(f"   ä»»åŠ¡ID: {result['task_id']}")
            if result.get("url"):
                print(f"   ä»»åŠ¡é“¾æ¥: {result['url']}")
        else:
            print(f"âŒ æ»´ç­”æ¸…å•ä»»åŠ¡åˆ›å»ºå¤±è´¥: {result.get('error', 'æœªçŸ¥é”™è¯¯')}")

    except Exception as e:
        print(f"âŒ åˆ›å»ºæ»´ç­”æ¸…å•ä»»åŠ¡æ—¶å‡ºé”™: {e}")


def main():
    """ä¸»å‡½æ•°"""
    try:
        # Google Sheets TSV å¯¼å‡ºé“¾æ¥
        tsv_url = "https://docs.google.com/spreadsheets/d/1itjnV2U-Eh0F1T0LIGuLjzIhgL9f_OD8tbkMUG-Onic/export?format=tsv&id=1itjnV2U-Eh0F1T0LIGuLjzIhgL9f_OD8tbkMUG-Onic&gid=0"

        print("ğŸ” æ¯æ—¥ç ”ç©¶è€…åŠ¨æ€ç›‘æ§ - è·å–ç‰¹å®šç ”ç©¶è€…å½“å¤©å‘å¸ƒçš„è®ºæ–‡")
        print(f"æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        print(f"URL: {tsv_url}\n")

        # è·å–ç ”ç©¶è€…æ•°æ®
        researchers = fetch_researchers_from_tsv(tsv_url)

        # æ˜¾ç¤ºç ”ç©¶è€…åˆ—è¡¨
        display_researchers(researchers)

        if researchers:
            # è·å–æ‰€æœ‰ç ”ç©¶è€…ä»Šå¤©å‘å¸ƒçš„è®ºæ–‡
            all_papers = get_today_papers_for_all_researchers(researchers)

            # æ˜¾ç¤ºè®ºæ–‡ç»“æœ
            display_papers(all_papers)

            print(f"\nâœ… ç›‘æ§å®Œæˆ - {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")

            # åˆ›å»ºæ»´ç­”æ¸…å•ä»»åŠ¡
            create_daily_dida_task(researchers, all_papers)

            return researchers, all_papers
        else:
            print("âš ï¸ æœªæ‰¾åˆ°ç ”ç©¶è€…æ•°æ®ï¼Œè¯·æ£€æŸ¥æ•°æ®æº")
            # å³ä½¿æ²¡æœ‰æ•°æ®ä¹Ÿåˆ›å»ºä¸€ä¸ªè®°å½•ä»»åŠ¡
            create_daily_dida_task([], {})
            return [], {}

    except Exception as e:
        print(f"âŒ ç¨‹åºæ‰§è¡Œå‡ºé”™: {e}")
        import traceback

        traceback.print_exc()
        # åˆ›å»ºé”™è¯¯è®°å½•ä»»åŠ¡
        create_daily_dida_task([], {}, error=str(e))
        return [], {}


if __name__ == "__main__":
    researchers_data, papers_data = main()
