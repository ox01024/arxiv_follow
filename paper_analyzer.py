#!/usr/bin/env python3
"""
è®ºæ–‡åˆ†ææ¨¡å— - ä½¿ç”¨LLMå¯¹è®ºæ–‡è¿›è¡Œæ·±åº¦åˆ†æå’ŒæŠ¥å‘Šç”Ÿæˆ
"""

import os
import httpx
import json
import logging
from typing import Dict, Any, List, Optional
from datetime import datetime

# å¯¼å…¥ç¿»è¯‘æœåŠ¡çš„åŸºç¡€è®¾æ–½
try:
    from translation_service import TranslationService
except ImportError:
    print("âš ï¸ æ— æ³•å¯¼å…¥ç¿»è¯‘æœåŠ¡ï¼Œå°†ä½¿ç”¨ç®€åŒ–ç‰ˆæœ¬")
    TranslationService = None

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class PaperAnalyzer:
    """è®ºæ–‡åˆ†æå™¨ - ä½¿ç”¨LLMåˆ†æè®ºæ–‡å†…å®¹"""
    
    def __init__(self, api_key: Optional[str] = None):
        """
        åˆå§‹åŒ–è®ºæ–‡åˆ†æå™¨
        
        Args:
            api_key: OpenRouter APIå¯†é’¥ï¼Œå¦‚æœä¸æä¾›ä¼šä»ç¯å¢ƒå˜é‡è¯»å–
        """
        self.api_key = api_key or os.getenv('OPEN_ROUTE_API_KEY')
        self.base_url = "https://openrouter.ai/api/v1"
        self.model = "google/gemini-2.0-flash-lite-001"
        
        if not self.api_key:
            logger.warning("æœªæ‰¾åˆ°OpenRouter APIå¯†é’¥ï¼Œåˆ†æåŠŸèƒ½å°†è¢«ç¦ç”¨")
            logger.info("è¯·è®¾ç½®ç¯å¢ƒå˜é‡: OPEN_ROUTE_API_KEY")
    
    def is_enabled(self) -> bool:
        """æ£€æŸ¥åˆ†æå™¨æ˜¯å¦å¯ç”¨"""
        return bool(self.api_key)
    
    def _call_llm(self, prompt: str, max_tokens: int = 2000) -> Optional[str]:
        """
        è°ƒç”¨LLM API
        
        Args:
            prompt: æç¤ºè¯
            max_tokens: æœ€å¤§tokenæ•°
            
        Returns:
            LLMå“åº”å†…å®¹
        """
        if not self.is_enabled():
            return None
        
        try:
            headers = {
                "Authorization": f"Bearer {self.api_key}",
                "Content-Type": "application/json",
                "HTTP-Referer": "https://github.com/arxiv-follow",
                "X-Title": "ArXiv Follow Paper Analysis Service"
            }
            
            data = {
                "model": self.model,
                "messages": [
                    {
                        "role": "user", 
                        "content": prompt
                    }
                ],
                "max_tokens": max_tokens,
                "temperature": 0.3,  # é™ä½éšæœºæ€§ï¼Œæé«˜åˆ†æçš„ä¸€è‡´æ€§
                "top_p": 0.9
            }
            
            with httpx.Client(timeout=60.0) as client:
                response = client.post(
                    f"{self.base_url}/chat/completions",
                    headers=headers,
                    json=data
                )
                response.raise_for_status()
                
                result = response.json()
                content = result["choices"][0]["message"]["content"]
                
                logger.info(f"LLMåˆ†æå®Œæˆï¼Œå“åº”é•¿åº¦: {len(content)}")
                return content
                
        except Exception as e:
            logger.error(f"LLM APIè°ƒç”¨å¤±è´¥: {e}")
            return None
    
    def analyze_paper_significance(self, paper_data: Dict[str, Any]) -> Dict[str, Any]:
        """
        åˆ†æè®ºæ–‡çš„é‡è¦æ€§å’Œæ„ä¹‰
        
        Args:
            paper_data: è®ºæ–‡æ•°æ®
            
        Returns:
            é‡è¦æ€§åˆ†æç»“æœ
        """
        if not self.is_enabled():
            return {"error": "åˆ†æå™¨æœªå¯ç”¨"}
        
        # æ„å»ºåˆ†ææç¤ºè¯
        title = paper_data.get('title', 'æœªçŸ¥æ ‡é¢˜')
        abstract = paper_data.get('abstract', 'æ— æ‘˜è¦')
        authors = paper_data.get('authors', [])
        subjects = paper_data.get('subjects', [])
        
        prompt = f"""è¯·åˆ†æä»¥ä¸‹å­¦æœ¯è®ºæ–‡çš„é‡è¦æ€§å’Œæ„ä¹‰ï¼š

è®ºæ–‡æ ‡é¢˜ï¼š{title}

ä½œè€…ï¼š{', '.join(authors) if authors else 'æœªçŸ¥'}

å­¦ç§‘åˆ†ç±»ï¼š{', '.join(subjects) if subjects else 'æœªçŸ¥'}

æ‘˜è¦ï¼š
{abstract}

è¯·ä»ä»¥ä¸‹è§’åº¦è¿›è¡Œåˆ†æï¼ˆç”¨ä¸­æ–‡å›ç­”ï¼‰ï¼š

1. **ç ”ç©¶æ„ä¹‰**ï¼šè¿™ä¸ªç ”ç©¶è§£å†³äº†ä»€ä¹ˆé—®é¢˜ï¼Ÿä¸ºä»€ä¹ˆé‡è¦ï¼Ÿ
2. **æŠ€æœ¯åˆ›æ–°ç‚¹**ï¼šæœ‰å“ªäº›æ–°çš„æ–¹æ³•ã€æŠ€æœ¯æˆ–ç†è®ºè´¡çŒ®ï¼Ÿ
3. **åº”ç”¨ä»·å€¼**ï¼šå¯èƒ½çš„å®é™…åº”ç”¨åœºæ™¯å’Œå½±å“ï¼Ÿ
4. **ç ”ç©¶è´¨é‡è¯„ä¼°**ï¼šåŸºäºæ‘˜è¦åˆ¤æ–­ç ”ç©¶çš„ä¸¥è°¨æ€§å’Œå®Œæ•´æ€§
5. **é‡è¦æ€§è¯„åˆ†**ï¼šç»™å‡º1-10åˆ†çš„é‡è¦æ€§è¯„åˆ†ï¼ˆ10åˆ†æœ€é«˜ï¼‰
6. **å…³é”®è¯æå–**ï¼šæå–5-8ä¸ªå…³é”®æŠ€æœ¯è¯æ±‡

è¯·ç”¨ç»“æ„åŒ–çš„æ–¹å¼å›ç­”ï¼Œæ¯ä¸ªéƒ¨åˆ†ç”¨ç®€æ´ä½†æœ‰è§åœ°çš„è¯­è¨€æ€»ç»“ã€‚
"""
        
        response = self._call_llm(prompt, max_tokens=1500)
        
        if response:
            return {
                "analysis_type": "significance",
                "content": response,
                "model": self.model,
                "analysis_time": datetime.now().isoformat(),
                "success": True
            }
        else:
            return {
                "error": "LLMåˆ†æå¤±è´¥",
                "success": False
            }
    
    def analyze_paper_technical_details(self, paper_data: Dict[str, Any]) -> Dict[str, Any]:
        """
        åˆ†æè®ºæ–‡çš„æŠ€æœ¯ç»†èŠ‚
        
        Args:
            paper_data: è®ºæ–‡æ•°æ®
            
        Returns:
            æŠ€æœ¯åˆ†æç»“æœ
        """
        if not self.is_enabled():
            return {"error": "åˆ†æå™¨æœªå¯ç”¨"}
        
        title = paper_data.get('title', 'æœªçŸ¥æ ‡é¢˜')
        abstract = paper_data.get('abstract', 'æ— æ‘˜è¦')
        sections = paper_data.get('sections', [])
        
        # å¦‚æœæœ‰ç« èŠ‚ä¿¡æ¯ï¼ŒåŒ…å«åœ¨åˆ†æä¸­
        sections_text = ""
        if sections:
            sections_text = "\n\nç« èŠ‚ä¿¡æ¯ï¼š\n"
            for section in sections[:5]:  # åªå–å‰5ä¸ªç« èŠ‚
                sections_text += f"- {section['title']}: {section['content']}\n"
        
        prompt = f"""è¯·å¯¹ä»¥ä¸‹å­¦æœ¯è®ºæ–‡è¿›è¡ŒæŠ€æœ¯æ·±åº¦åˆ†æï¼š

è®ºæ–‡æ ‡é¢˜ï¼š{title}

æ‘˜è¦ï¼š
{abstract}
{sections_text}

è¯·ä»æŠ€æœ¯è§’åº¦è¿›è¡Œè¯¦ç»†åˆ†æï¼ˆç”¨ä¸­æ–‡å›ç­”ï¼‰ï¼š

1. **æ–¹æ³•è®ºåˆ†æ**ï¼šä½¿ç”¨äº†å“ªäº›ç ”ç©¶æ–¹æ³•å’ŒæŠ€æœ¯æ‰‹æ®µï¼Ÿ
2. **ç®—æ³•/æ¨¡å‹è¯¦è§£**ï¼šæ ¸å¿ƒç®—æ³•æˆ–æ¨¡å‹çš„å·¥ä½œåŸç†æ˜¯ä»€ä¹ˆï¼Ÿ
3. **å®éªŒè®¾è®¡**ï¼šå®éªŒæ˜¯å¦‚ä½•è®¾è®¡çš„ï¼Ÿä½¿ç”¨äº†ä»€ä¹ˆæ•°æ®é›†ï¼Ÿ
4. **æŠ€æœ¯éš¾ç‚¹**ï¼šè§£å†³äº†å“ªäº›æŠ€æœ¯æŒ‘æˆ˜ï¼Ÿ
5. **ä¸ç°æœ‰å·¥ä½œçš„å…³ç³»**ï¼šå¦‚ä½•åœ¨ç°æœ‰ç ”ç©¶åŸºç¡€ä¸Šæ”¹è¿›ï¼Ÿ
6. **å¯é‡ç°æ€§è¯„ä¼°**ï¼šå®éªŒçš„å¯é‡ç°æ€§å¦‚ä½•ï¼Ÿ
7. **æŠ€æœ¯å±€é™æ€§**ï¼šå­˜åœ¨å“ªäº›æŠ€æœ¯é™åˆ¶æˆ–ä¸è¶³ï¼Ÿ

è¯·ç”¨ä¸“ä¸šä½†æ˜“æ‡‚çš„è¯­è¨€è¿›è¡Œåˆ†æï¼Œé‡ç‚¹çªå‡ºæŠ€æœ¯è´¡çŒ®ã€‚
"""
        
        response = self._call_llm(prompt, max_tokens=2000)
        
        if response:
            return {
                "analysis_type": "technical",
                "content": response,
                "model": self.model,
                "analysis_time": datetime.now().isoformat(),
                "success": True
            }
        else:
            return {
                "error": "LLMæŠ€æœ¯åˆ†æå¤±è´¥",
                "success": False
            }
    
    def generate_comprehensive_report(self, paper_data: Dict[str, Any]) -> Dict[str, Any]:
        """
        ç”Ÿæˆç»¼åˆåˆ†ææŠ¥å‘Š
        
        Args:
            paper_data: è®ºæ–‡æ•°æ®
            
        Returns:
            ç»¼åˆæŠ¥å‘Š
        """
        if not self.is_enabled():
            return {"error": "åˆ†æå™¨æœªå¯ç”¨"}
        
        logger.info(f"å¼€å§‹ç”Ÿæˆç»¼åˆæŠ¥å‘Š: {paper_data.get('title', 'unknown')}")
        
        # è·å–å¤šä¸ªç»´åº¦çš„åˆ†æ
        significance_analysis = self.analyze_paper_significance(paper_data)
        technical_analysis = self.analyze_paper_technical_details(paper_data)
        
        # ç”Ÿæˆæœ€ç»ˆç»¼åˆæŠ¥å‘Š
        title = paper_data.get('title', 'æœªçŸ¥æ ‡é¢˜')
        arxiv_id = paper_data.get('arxiv_id', 'æœªçŸ¥ID')
        authors = paper_data.get('authors', [])
        
        prompt = f"""åŸºäºä»¥ä¸‹è®ºæ–‡çš„å¤šç»´åº¦åˆ†æï¼Œç”Ÿæˆä¸€ä»½ç®€æ´ä½†å…¨é¢çš„åˆ†ææŠ¥å‘Šï¼š

è®ºæ–‡ï¼š{title} (arXiv:{arxiv_id})
ä½œè€…ï¼š{', '.join(authors[:5]) if authors else 'æœªçŸ¥'}

é‡è¦æ€§åˆ†æï¼š
{significance_analysis.get('content', 'åˆ†æå¤±è´¥')}

æŠ€æœ¯åˆ†æï¼š
{technical_analysis.get('content', 'åˆ†æå¤±è´¥')}

è¯·ç”Ÿæˆä¸€ä»½ç»“æ„åŒ–çš„ç»¼åˆæŠ¥å‘Šï¼ŒåŒ…å«ï¼š

ğŸ“Š **è®ºæ–‡æ¦‚è§ˆ**
- åŸºæœ¬ä¿¡æ¯å’Œç ”ç©¶èƒŒæ™¯

ğŸ”¬ **æ ¸å¿ƒè´¡çŒ®**
- ä¸»è¦æŠ€æœ¯åˆ›æ–°ï¼ˆ3-4ä¸ªè¦ç‚¹ï¼‰

âš¡ **é‡ç‚¹äº®ç‚¹** 
- æœ€å€¼å¾—å…³æ³¨çš„åˆ›æ–°ç‚¹ï¼ˆ2-3ä¸ªï¼‰

ğŸ¯ **åº”ç”¨å‰æ™¯**
- å®é™…åº”ç”¨ä»·å€¼å’Œæ½œåœ¨å½±å“

ğŸ“ˆ **æ¨èæŒ‡æ•°**
- ç»¼åˆè¯„åˆ†ï¼ˆ1-10åˆ†ï¼‰å’Œæ¨èç†ç”±

è¯·ç”¨markdownæ ¼å¼ï¼Œè¯­è¨€ç®€æ´ä¸“ä¸šï¼Œé€‚åˆä½œä¸ºç ”ç©¶ç®€æŠ¥ã€‚
"""
        
        response = self._call_llm(prompt, max_tokens=1800)
        
        if response:
            return {
                "report_type": "comprehensive",
                "paper_id": arxiv_id,
                "paper_title": title,
                "report_content": response,
                "model": self.model,
                "generation_time": datetime.now().isoformat(),
                "success": True,
                "analysis_components": {
                    "significance": significance_analysis.get('success', False),
                    "technical": technical_analysis.get('success', False)
                }
            }
        else:
            return {
                "error": "ç»¼åˆæŠ¥å‘Šç”Ÿæˆå¤±è´¥",
                "success": False
            }
    
    def analyze_multiple_papers(self, papers_data: List[Dict[str, Any]], mode: str = "significance") -> List[Dict[str, Any]]:
        """
        æ‰¹é‡åˆ†æå¤šç¯‡è®ºæ–‡
        
        Args:
            papers_data: è®ºæ–‡æ•°æ®åˆ—è¡¨
            mode: åˆ†ææ¨¡å¼ ("significance", "technical", "comprehensive")
            
        Returns:
            åˆ†æç»“æœåˆ—è¡¨
        """
        if not self.is_enabled():
            return [{"error": "åˆ†æå™¨æœªå¯ç”¨"} for _ in papers_data]
        
        logger.info(f"å¼€å§‹æ‰¹é‡åˆ†æ {len(papers_data)} ç¯‡è®ºæ–‡ï¼Œæ¨¡å¼: {mode}")
        
        results = []
        
        for i, paper_data in enumerate(papers_data):
            try:
                if mode == "significance":
                    result = self.analyze_paper_significance(paper_data)
                elif mode == "technical":
                    result = self.analyze_paper_technical_details(paper_data)
                elif mode == "comprehensive":
                    result = self.generate_comprehensive_report(paper_data)
                else:
                    result = {"error": f"æœªçŸ¥åˆ†ææ¨¡å¼: {mode}"}
                
                result['paper_index'] = i
                result['paper_id'] = paper_data.get('arxiv_id', f'paper_{i}')
                results.append(result)
                
                # è¿›åº¦æ˜¾ç¤º
                if i % 3 == 0 or i == len(papers_data) - 1:
                    logger.info(f"åˆ†æè¿›åº¦: {i + 1}/{len(papers_data)}")
                
            except Exception as e:
                logger.error(f"åˆ†æè®ºæ–‡ {i} æ—¶å‡ºé”™: {e}")
                results.append({
                    "error": str(e),
                    "paper_index": i,
                    "paper_id": paper_data.get('arxiv_id', f'paper_{i}')
                })
        
        success_count = len([r for r in results if r.get('success')])
        logger.info(f"æ‰¹é‡åˆ†æå®Œæˆï¼ŒæˆåŠŸ: {success_count}/{len(papers_data)}")
        
        return results
    
    def generate_daily_summary(self, papers_analysis: List[Dict[str, Any]]) -> Dict[str, Any]:
        """
        ç”Ÿæˆæ¯æ—¥è®ºæ–‡æ€»ç»“æŠ¥å‘Š
        
        Args:
            papers_analysis: è®ºæ–‡åˆ†æç»“æœåˆ—è¡¨
            
        Returns:
            æ¯æ—¥æ€»ç»“æŠ¥å‘Š
        """
        if not self.is_enabled():
            return {"error": "åˆ†æå™¨æœªå¯ç”¨"}
        
        # è¿‡æ»¤æˆåŠŸçš„åˆ†æ
        successful_analyses = [a for a in papers_analysis if a.get('success')]
        
        if not successful_analyses:
            return {"error": "æ²¡æœ‰æˆåŠŸçš„è®ºæ–‡åˆ†æç»“æœ"}
        
        # æ„å»ºæ€»ç»“æç¤ºè¯
        papers_summary = "\n\n".join([
                            f"è®ºæ–‡ {i+1}: {analysis.get('paper_id', 'unknown')}\nå†…å®¹æ‘˜è¦:\n{analysis.get('report_content', analysis.get('content', ''))}"
            for i, analysis in enumerate(successful_analyses[:10])  # æœ€å¤šæ€»ç»“10ç¯‡
        ])
        
        prompt = f"""åŸºäºä»Šæ—¥æ”¶é›†çš„ {len(successful_analyses)} ç¯‡è®ºæ–‡åˆ†æï¼Œç”Ÿæˆæ¯æ—¥ç ”ç©¶ç®€æŠ¥ï¼š

{papers_summary}

è¯·ç”Ÿæˆä¸€ä»½æ¯æ—¥ç®€æŠ¥ï¼ŒåŒ…å«ï¼š

ğŸ“… **ä»Šæ—¥æ¦‚è§ˆ**
- è®ºæ–‡æ•°é‡å’Œä¸»è¦ç ”ç©¶é¢†åŸŸåˆ†å¸ƒ

ğŸ”¥ **çƒ­ç‚¹è¶‹åŠ¿** 
- è¯†åˆ«å‡ºçš„ç ”ç©¶çƒ­ç‚¹å’Œè¶‹åŠ¿ï¼ˆ3-4ä¸ªï¼‰

ğŸ’ **ç²¾é€‰æ¨è**
- æœ€å€¼å¾—å…³æ³¨çš„2-3ç¯‡è®ºæ–‡ï¼ˆè¯´æ˜ç†ç”±ï¼‰

ğŸ§  **æŠ€æœ¯æ´å¯Ÿ**
- æ–°å…´æŠ€æœ¯æ–¹å‘å’Œé‡è¦è¿›å±•

ğŸ“Š **å½±å“è¯„ä¼°**
- å¯¹ç›¸å…³ç ”ç©¶é¢†åŸŸå¯èƒ½äº§ç”Ÿçš„å½±å“

è¯·ç”¨markdownæ ¼å¼ï¼Œç®€æ´ä¸“ä¸šï¼Œé€‚åˆä½œä¸ºç ”ç©¶åŠ¨æ€ç®€æŠ¥ã€‚
"""
        
        response = self._call_llm(prompt, max_tokens=2000)
        
        if response:
            return {
                "summary_type": "daily",
                "papers_count": len(successful_analyses),
                "total_papers": len(papers_analysis),
                "summary_content": response,
                "model": self.model,
                "generation_time": datetime.now().isoformat(),
                "success": True
            }
        else:
            return {
                "error": "æ¯æ—¥ç®€æŠ¥ç”Ÿæˆå¤±è´¥",
                "success": False
            }


def analyze_paper(paper_data: Dict[str, Any], mode: str = "comprehensive") -> Dict[str, Any]:
    """
    ä¾¿æ·å‡½æ•°ï¼šåˆ†æå•ç¯‡è®ºæ–‡
    
    Args:
        paper_data: è®ºæ–‡æ•°æ®
        mode: åˆ†ææ¨¡å¼
        
    Returns:
        åˆ†æç»“æœ
    """
    analyzer = PaperAnalyzer()
    
    if mode == "significance":
        return analyzer.analyze_paper_significance(paper_data)
    elif mode == "technical":
        return analyzer.analyze_paper_technical_details(paper_data)
    else:
        return analyzer.generate_comprehensive_report(paper_data)


def analyze_multiple_papers(papers_data: List[Dict[str, Any]], mode: str = "comprehensive") -> List[Dict[str, Any]]:
    """
    ä¾¿æ·å‡½æ•°ï¼šæ‰¹é‡åˆ†æè®ºæ–‡
    
    Args:
        papers_data: è®ºæ–‡æ•°æ®åˆ—è¡¨
        mode: åˆ†ææ¨¡å¼
        
    Returns:
        åˆ†æç»“æœåˆ—è¡¨
    """
    analyzer = PaperAnalyzer()
    return analyzer.analyze_multiple_papers(papers_data, mode)


if __name__ == "__main__":
    # æµ‹è¯•ä»£ç 
    print("ğŸ§ª æµ‹è¯•è®ºæ–‡åˆ†æåŠŸèƒ½")
    
    # ç¤ºä¾‹è®ºæ–‡æ•°æ®
    test_paper = {
        "arxiv_id": "2501.12345",
        "title": "Transformer-based Anomaly Detection in Network Traffic",
        "authors": ["Zhang Wei", "Li Ming"],
        "abstract": "This paper presents a novel approach for detecting anomalies in network traffic using transformer architectures. We propose a self-supervised learning framework that can identify unusual patterns without requiring labeled data...",
        "subjects": ["cs.AI", "cs.CR"]
    }
    
    analyzer = PaperAnalyzer()
    
    if analyzer.is_enabled():
        print("âœ… åˆ†æå™¨å·²å¯ç”¨ï¼Œå¼€å§‹æµ‹è¯•...")
        
        # æµ‹è¯•é‡è¦æ€§åˆ†æ
        print("\nğŸ“Š æµ‹è¯•é‡è¦æ€§åˆ†æ...")
        sig_result = analyzer.analyze_paper_significance(test_paper)
        if sig_result.get('success'):
            print("âœ… é‡è¦æ€§åˆ†ææˆåŠŸ")
            print(f"å†…å®¹é•¿åº¦: {len(sig_result.get('content', ''))}")
        else:
            print(f"âŒ é‡è¦æ€§åˆ†æå¤±è´¥: {sig_result.get('error')}")
        
        # æµ‹è¯•ç»¼åˆæŠ¥å‘Š
        print("\nğŸ“‹ æµ‹è¯•ç»¼åˆæŠ¥å‘Šç”Ÿæˆ...")
        report_result = analyzer.generate_comprehensive_report(test_paper)
        if report_result.get('success'):
            print("âœ… ç»¼åˆæŠ¥å‘Šç”ŸæˆæˆåŠŸ")
            print("\næŠ¥å‘Šå†…å®¹é¢„è§ˆ:")
            print(report_result.get('report_content', '')[:300] + "...")
        else:
            print(f"âŒ ç»¼åˆæŠ¥å‘Šç”Ÿæˆå¤±è´¥: {report_result.get('error')}")
    
    else:
        print("âŒ åˆ†æå™¨æœªå¯ç”¨ï¼Œè¯·è®¾ç½® OPEN_ROUTE_API_KEY ç¯å¢ƒå˜é‡") 